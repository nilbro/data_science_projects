{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkContext and RDD Basics\n",
    "\n",
    "#### Resilient Distributed Datasets (RDD) is a fundamental data structure of Spark. It is an immutable distributed collection of objects. Each dataset in RDD is divided into logical partitions, which may be computed on different nodes of the cluster. RDDs can contain any type of Python, Java, or Scala objects, including user-defined classes.\n",
    "\n",
    "#### Spark makes use of the concept of RDD to achieve faster and efficient MapReduce operations.\n",
    "\n",
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a SparkContext which uses 4 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "sc=SparkContext(master=\"local[4]\")\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Parallelization\n",
    "#### RDD can be created in 2 ways:\n",
    "1. parallelizing an existing collection in your driver program\n",
    "2. referencing a dataset in an external storage system, such as a shared file system, HDFS, HBase, or any data source offering a Hadoop Input Format.\n",
    "\n",
    "#### Lets create a RDD by the first method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 8 9 2 2 6 1 5 1 7 0 0 8 0 9 4 7 1 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = np.random.randint(0,10,20)\n",
    "print(lst)\n",
    "A = sc.parallelize(lst)\n",
    "type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since 4 cores were used, the list was parallelized into 4 sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 8, 9, 2], [2, 6, 1, 5, 1], [7, 0, 0, 8, 0], [9, 4, 7, 1, 6]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the same with  2 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 8, 9, 2, 2, 6, 1, 5, 1], [7, 0, 0, 8, 0, 9, 4, 7, 1, 6]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.stop()\n",
    "sc=SparkContext(master=\"local[2]\")\n",
    "A = sc.parallelize(lst)\n",
    "A.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "sc=SparkContext(master=\"local[4]\")\n",
    "A = sc.parallelize(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic RDD Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### access first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### access first few (4) elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 8, 9]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create rdd with duplicates removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 0, 9, 1, 5, 2, 6, 3, 7]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_distinct=A.distinct()\n",
    "A_distinct.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum\n",
    "#### Reduce method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct sum method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fold method: Aggregates each partition first and then result of each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.fold(0,lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum element/ longest word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maximum element by reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.reduce(lambda x,y: x if x>y else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### longest word by reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distributed'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'In Apache Spark a DataFrame is a distributed collection of rows under named columns'.split(' ')\n",
    "wordsRDD = sc.parallelize(words)\n",
    "wordsRDD.reduce(lambda x,y: x if len(x)>len(y) else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions/filtering in RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 9, 6, 0, 0, 0, 9, 6]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.filter(lambda x: x%3==0).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda functions are short and sweet but we can write regular Python functions to use with reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largerThan(x,y):\n",
    "    \"\"\"\n",
    "    Returns the last word among the longest words in a list\n",
    "    \"\"\"\n",
    "    if len(x)> len(y):\n",
    "        return x\n",
    "    else:\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distributed'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsRDD.reduce(largerThan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD sampling\n",
    "#### RDDs are often very large. Aggregates, such as averages, can be approximated efficiently by using a sample. This comes handy often for operation with extremely large datasets where a sample can tell a lot about the pattern and descriptive statistics of the data.\n",
    "#### Sampling is done in parallel and requires limited computation.\n",
    "\n",
    "#### The method RDD.sample(withReplacement,p) generates a sample of the elements of the RDD. where \n",
    "1. withReplacement is a boolean flag indicating whether or not a an element in the RDD can be sampled more than once.\n",
    "2. p is the probability of accepting each element into the sample. Note that as the sampling is performed independently in each partition, the number of elements in the sample changes from sample to sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample1= [3, 4, 1, 5, 1, 0, 8]\n",
      "sample2= [4, 6, 1, 0, 8, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "# get a sample whose expected size is m\n",
    "# Note that the size of the sample is different in different runs\n",
    "m=5\n",
    "n=20\n",
    "print('sample1=',A.sample(False,m/n).collect()) \n",
    "print('sample2=',A.sample(False,m/n).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to note and think about\n",
    "### Each time you run the previous cell, you get a different estimate. The accuracy of the estimate is determined by the size of the sample $n*p$. Here, probability $p=\\frac{m}{n}$ .See how the error changes as you vary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum:  9\n",
      "Minimum:  0\n",
      "Mean (average):  4.15\n",
      "Standard deviation:  3.10282129682\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum: \",A.max())\n",
    "print(\"Minimum: \",A.min())\n",
    "print(\"Mean (average): \",A.mean())\n",
    "print(\"Standard deviation: \",A.stdev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 20, mean: 4.15, stdev: 3.10282129682, max: 9.0, min: 0.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 16, 64, 81, 4, 4, 36, 1, 25, 1, 49, 0, 0, 64, 0, 81, 16, 49, 1, 36]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=A.map(lambda x:x*x)\n",
    "B.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with regular python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 4, 8, 81, 2, 2, 6, 1, 25, 1, 49, 0, 0, 8, 0, 81, 4, 49, 1, 6]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_if_odd(x):\n",
    "    if x%2==1:\n",
    "        return x*x\n",
    "    else:\n",
    "        return x\n",
    "A.map(square_if_odd).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatmapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flatmap method returns a new RDD by first applying a function to all elements of this RDD, and then flattening the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 9,\n",
       " 4,\n",
       " 16,\n",
       " 8,\n",
       " 64,\n",
       " 9,\n",
       " 81,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 36,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 25,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 64,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 81,\n",
       " 4,\n",
       " 16,\n",
       " 7,\n",
       " 49,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 36]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.flatMap(lambda x:(x,x*x)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map(func) Return a new distributed dataset formed by passing each element of the source through a function func. N inputs, N outputs\n",
    "\n",
    "* sc.parallelize([3,4,5]).map(lambda x: [x,  x*x]).collect() \n",
    "#### **Output:**\n",
    "[[3, 9], [4, 16], [5, 25]]\n",
    "\n",
    "#### flatMap(func) Similar to map, but each input item can be mapped to 0 or more output items (so func should return a Seq rather than a single item).\n",
    "* sc.parallelize([3,4,5]).flatMap(lambda x: [x, x*x]).collect() \n",
    "#### Output: notice flattened list\n",
    "[3, 9, 4, 16, 5, 25]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and binning\n",
    "#### groupBy works same way as in sql. It groups the elements of a dataframe by a field or a function.\n",
    "#### here groupBy is shown with a lambda function, where the elements are grouped according to their reminder when multiplied by 2. It returns a List of RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [0, 0, 0, 2, 2, 4, 4, 6, 6, 8, 8]), (1, [1, 1, 1, 3, 5, 7, 7, 9, 9])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=A.groupBy(lambda x:x%2).collect()\n",
    "sorted([(x, sorted(y)) for (x, y) in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### histogram method takes a list of bins/buckets and returns a tuple with result of the histogram (binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 16, 64, 81, 4, 4, 36, 1, 25, 1, 49, 0, 0, 64, 0, 81, 16, 49, 1, 36]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 10, 20, 30, 40, 50, 60, 70, 80, 90], [9, 2, 1, 2, 2, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.histogram([x for x in range(0,100,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here the first element of the tuple is a list of x as defined. The second element is a list of the number of elements of B, which falls in each range. For example there are 9 elements in B which falls between 0 and 10, 2 elements fall between 10 and 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [3, 4, 8, 9, 2, 2, 6, 1, 5, 1, 7, 0, 0, 8, 0, 9, 4, 7, 1, 6]\n",
      "B: [9, 16, 64, 81, 4, 4, 36, 1, 25, 1, 49, 0, 0, 64, 0, 81, 16, 49, 1, 36]\n"
     ]
    }
   ],
   "source": [
    "print(\"A:\",A.collect())\n",
    "print(\"B:\",B.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union, Intersection, subtraction, cartesian product of two rdds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 16,\n",
       " 64,\n",
       " 81,\n",
       " 4,\n",
       " 4,\n",
       " 36,\n",
       " 1,\n",
       " 25,\n",
       " 1,\n",
       " 49,\n",
       " 0,\n",
       " 0,\n",
       " 64,\n",
       " 0,\n",
       " 81,\n",
       " 16,\n",
       " 49,\n",
       " 1,\n",
       " 36]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A+B).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 9, 1, 4]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.intersection(B).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 2, 2, 3, 5, 6, 6, 7, 7]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.subtract(B).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cartesian product gives all possible combinations of all elements in two RDD. each product is a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 9),\n",
       " (4, 9),\n",
       " (8, 9),\n",
       " (9, 9),\n",
       " (2, 9),\n",
       " (3, 16),\n",
       " (3, 64),\n",
       " (4, 16),\n",
       " (4, 64),\n",
       " (8, 16),\n",
       " (8, 64),\n",
       " (9, 16),\n",
       " (9, 64),\n",
       " (2, 16),\n",
       " (2, 64),\n",
       " (3, 81),\n",
       " (3, 4),\n",
       " (4, 81),\n",
       " (4, 4),\n",
       " (8, 81),\n",
       " (8, 4),\n",
       " (9, 81),\n",
       " (9, 4),\n",
       " (2, 81),\n",
       " (2, 4),\n",
       " (3, 4),\n",
       " (4, 4),\n",
       " (8, 4),\n",
       " (9, 4),\n",
       " (2, 4),\n",
       " (3, 36),\n",
       " (3, 1),\n",
       " (4, 36),\n",
       " (4, 1),\n",
       " (8, 36),\n",
       " (8, 1),\n",
       " (9, 36),\n",
       " (9, 1),\n",
       " (2, 36),\n",
       " (2, 1),\n",
       " (3, 25),\n",
       " (3, 1),\n",
       " (4, 25),\n",
       " (4, 1),\n",
       " (8, 25),\n",
       " (8, 1),\n",
       " (9, 25),\n",
       " (9, 1),\n",
       " (2, 25),\n",
       " (2, 1),\n",
       " (3, 49),\n",
       " (4, 49),\n",
       " (8, 49),\n",
       " (9, 49),\n",
       " (2, 49),\n",
       " (3, 0),\n",
       " (3, 0),\n",
       " (4, 0),\n",
       " (4, 0),\n",
       " (8, 0),\n",
       " (8, 0),\n",
       " (9, 0),\n",
       " (9, 0),\n",
       " (2, 0),\n",
       " (2, 0),\n",
       " (3, 64),\n",
       " (3, 0),\n",
       " (4, 64),\n",
       " (4, 0),\n",
       " (8, 64),\n",
       " (8, 0),\n",
       " (9, 64),\n",
       " (9, 0),\n",
       " (2, 64),\n",
       " (2, 0),\n",
       " (3, 81),\n",
       " (4, 81),\n",
       " (8, 81),\n",
       " (9, 81),\n",
       " (2, 81),\n",
       " (3, 16),\n",
       " (3, 49),\n",
       " (4, 16),\n",
       " (4, 49),\n",
       " (8, 16),\n",
       " (8, 49),\n",
       " (9, 16),\n",
       " (9, 49),\n",
       " (2, 16),\n",
       " (2, 49),\n",
       " (3, 1),\n",
       " (3, 36),\n",
       " (4, 1),\n",
       " (4, 36),\n",
       " (8, 1),\n",
       " (8, 36),\n",
       " (9, 1),\n",
       " (9, 36),\n",
       " (2, 1),\n",
       " (2, 36),\n",
       " (2, 9),\n",
       " (6, 9),\n",
       " (1, 9),\n",
       " (5, 9),\n",
       " (1, 9),\n",
       " (2, 16),\n",
       " (2, 64),\n",
       " (6, 16),\n",
       " (6, 64),\n",
       " (1, 16),\n",
       " (1, 64),\n",
       " (5, 16),\n",
       " (5, 64),\n",
       " (1, 16),\n",
       " (1, 64),\n",
       " (2, 81),\n",
       " (2, 4),\n",
       " (6, 81),\n",
       " (6, 4),\n",
       " (1, 81),\n",
       " (1, 4),\n",
       " (5, 81),\n",
       " (5, 4),\n",
       " (1, 81),\n",
       " (1, 4),\n",
       " (2, 4),\n",
       " (6, 4),\n",
       " (1, 4),\n",
       " (5, 4),\n",
       " (1, 4),\n",
       " (2, 36),\n",
       " (2, 1),\n",
       " (6, 36),\n",
       " (6, 1),\n",
       " (1, 36),\n",
       " (1, 1),\n",
       " (5, 36),\n",
       " (5, 1),\n",
       " (1, 36),\n",
       " (1, 1),\n",
       " (2, 25),\n",
       " (2, 1),\n",
       " (6, 25),\n",
       " (6, 1),\n",
       " (1, 25),\n",
       " (1, 1),\n",
       " (5, 25),\n",
       " (5, 1),\n",
       " (1, 25),\n",
       " (1, 1),\n",
       " (2, 49),\n",
       " (6, 49),\n",
       " (1, 49),\n",
       " (5, 49),\n",
       " (1, 49),\n",
       " (2, 0),\n",
       " (2, 0),\n",
       " (6, 0),\n",
       " (6, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (5, 0),\n",
       " (5, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (2, 64),\n",
       " (2, 0),\n",
       " (6, 64),\n",
       " (6, 0),\n",
       " (1, 64),\n",
       " (1, 0),\n",
       " (5, 64),\n",
       " (5, 0),\n",
       " (1, 64),\n",
       " (1, 0),\n",
       " (2, 81),\n",
       " (6, 81),\n",
       " (1, 81),\n",
       " (5, 81),\n",
       " (1, 81),\n",
       " (2, 16),\n",
       " (2, 49),\n",
       " (6, 16),\n",
       " (6, 49),\n",
       " (1, 16),\n",
       " (1, 49),\n",
       " (5, 16),\n",
       " (5, 49),\n",
       " (1, 16),\n",
       " (1, 49),\n",
       " (2, 1),\n",
       " (2, 36),\n",
       " (6, 1),\n",
       " (6, 36),\n",
       " (1, 1),\n",
       " (1, 36),\n",
       " (5, 1),\n",
       " (5, 36),\n",
       " (1, 1),\n",
       " (1, 36),\n",
       " (7, 9),\n",
       " (0, 9),\n",
       " (0, 9),\n",
       " (8, 9),\n",
       " (0, 9),\n",
       " (7, 16),\n",
       " (7, 64),\n",
       " (0, 16),\n",
       " (0, 64),\n",
       " (0, 16),\n",
       " (0, 64),\n",
       " (8, 16),\n",
       " (8, 64),\n",
       " (0, 16),\n",
       " (0, 64),\n",
       " (7, 81),\n",
       " (7, 4),\n",
       " (0, 81),\n",
       " (0, 4),\n",
       " (0, 81),\n",
       " (0, 4),\n",
       " (8, 81),\n",
       " (8, 4),\n",
       " (0, 81),\n",
       " (0, 4),\n",
       " (7, 4),\n",
       " (0, 4),\n",
       " (0, 4),\n",
       " (8, 4),\n",
       " (0, 4),\n",
       " (7, 36),\n",
       " (7, 1),\n",
       " (0, 36),\n",
       " (0, 1),\n",
       " (0, 36),\n",
       " (0, 1),\n",
       " (8, 36),\n",
       " (8, 1),\n",
       " (0, 36),\n",
       " (0, 1),\n",
       " (7, 25),\n",
       " (7, 1),\n",
       " (0, 25),\n",
       " (0, 1),\n",
       " (0, 25),\n",
       " (0, 1),\n",
       " (8, 25),\n",
       " (8, 1),\n",
       " (0, 25),\n",
       " (0, 1),\n",
       " (7, 49),\n",
       " (0, 49),\n",
       " (0, 49),\n",
       " (8, 49),\n",
       " (0, 49),\n",
       " (7, 0),\n",
       " (7, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (8, 0),\n",
       " (8, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (7, 64),\n",
       " (7, 0),\n",
       " (0, 64),\n",
       " (0, 0),\n",
       " (0, 64),\n",
       " (0, 0),\n",
       " (8, 64),\n",
       " (8, 0),\n",
       " (0, 64),\n",
       " (0, 0),\n",
       " (7, 81),\n",
       " (0, 81),\n",
       " (0, 81),\n",
       " (8, 81),\n",
       " (0, 81),\n",
       " (7, 16),\n",
       " (7, 49),\n",
       " (0, 16),\n",
       " (0, 49),\n",
       " (0, 16),\n",
       " (0, 49),\n",
       " (8, 16),\n",
       " (8, 49),\n",
       " (0, 16),\n",
       " (0, 49),\n",
       " (7, 1),\n",
       " (7, 36),\n",
       " (0, 1),\n",
       " (0, 36),\n",
       " (0, 1),\n",
       " (0, 36),\n",
       " (8, 1),\n",
       " (8, 36),\n",
       " (0, 1),\n",
       " (0, 36),\n",
       " (9, 9),\n",
       " (4, 9),\n",
       " (7, 9),\n",
       " (1, 9),\n",
       " (6, 9),\n",
       " (9, 16),\n",
       " (9, 64),\n",
       " (4, 16),\n",
       " (4, 64),\n",
       " (7, 16),\n",
       " (7, 64),\n",
       " (1, 16),\n",
       " (1, 64),\n",
       " (6, 16),\n",
       " (6, 64),\n",
       " (9, 81),\n",
       " (9, 4),\n",
       " (4, 81),\n",
       " (4, 4),\n",
       " (7, 81),\n",
       " (7, 4),\n",
       " (1, 81),\n",
       " (1, 4),\n",
       " (6, 81),\n",
       " (6, 4),\n",
       " (9, 4),\n",
       " (4, 4),\n",
       " (7, 4),\n",
       " (1, 4),\n",
       " (6, 4),\n",
       " (9, 36),\n",
       " (9, 1),\n",
       " (4, 36),\n",
       " (4, 1),\n",
       " (7, 36),\n",
       " (7, 1),\n",
       " (1, 36),\n",
       " (1, 1),\n",
       " (6, 36),\n",
       " (6, 1),\n",
       " (9, 25),\n",
       " (9, 1),\n",
       " (4, 25),\n",
       " (4, 1),\n",
       " (7, 25),\n",
       " (7, 1),\n",
       " (1, 25),\n",
       " (1, 1),\n",
       " (6, 25),\n",
       " (6, 1),\n",
       " (9, 49),\n",
       " (4, 49),\n",
       " (7, 49),\n",
       " (1, 49),\n",
       " (6, 49),\n",
       " (9, 0),\n",
       " (9, 0),\n",
       " (4, 0),\n",
       " (4, 0),\n",
       " (7, 0),\n",
       " (7, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (6, 0),\n",
       " (6, 0),\n",
       " (9, 64),\n",
       " (9, 0),\n",
       " (4, 64),\n",
       " (4, 0),\n",
       " (7, 64),\n",
       " (7, 0),\n",
       " (1, 64),\n",
       " (1, 0),\n",
       " (6, 64),\n",
       " (6, 0),\n",
       " (9, 81),\n",
       " (4, 81),\n",
       " (7, 81),\n",
       " (1, 81),\n",
       " (6, 81),\n",
       " (9, 16),\n",
       " (9, 49),\n",
       " (4, 16),\n",
       " (4, 49),\n",
       " (7, 16),\n",
       " (7, 49),\n",
       " (1, 16),\n",
       " (1, 49),\n",
       " (6, 16),\n",
       " (6, 49),\n",
       " (9, 1),\n",
       " (9, 36),\n",
       " (4, 1),\n",
       " (4, 36),\n",
       " (7, 1),\n",
       " (7, 36),\n",
       " (1, 1),\n",
       " (1, 36),\n",
       " (6, 1),\n",
       " (6, 36)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cartesian(B).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thats all from"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
