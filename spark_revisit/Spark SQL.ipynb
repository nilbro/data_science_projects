{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import and create a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark1 = SparkSession.builder.appName('SQL').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a dataframe from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark1.read.csv('appl_data.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date: timestamp, Open: double, High: double, Low: double, Close: double, Volume: int, Adj Close: double]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a temporary view on the Dataframe to perform Spark SQL queries on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('stock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result from the SQL query returns a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark1.sql('SELECT * FROM stock LIMIT 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date: timestamp, Open: double, High: double, Low: double, Close: double, Volume: int, Adj Close: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|               Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|\n",
      "+-------------------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04 00:00:00|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05 00:00:00|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06 00:00:00|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07 00:00:00|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08 00:00:00|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "+-------------------+----------+----------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL queries examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_greater_500 = spark1.sql('SELECT count(*) FROM stock WHERE Close > 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     403|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_greater_500.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_1 = spark1.sql('SELECT avg(OPEN) from stock WHERE Volume > 120000000 or Volume < 110000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         avg(OPEN)|\n",
      "+------------------+\n",
      "|309.12406365290224|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a dataframe from an external file using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = spark1.sql(\"SELECT * FROM csv.`sales.csv`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|    _c0|    _c1|  _c2|\n",
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "|   GOOG|    Sam|  200|\n",
      "|   GOOG|Charlie|  120|\n",
      "|   GOOG|  Frank|  340|\n",
      "|   MSFT|   Tina|  600|\n",
      "|   MSFT|    Amy|  124|\n",
      "|   MSFT|Vanessa|  243|\n",
      "|     FB|   Carl|  870|\n",
      "|     FB|  Sarah|  350|\n",
      "|   APPL|   John|  250|\n",
      "|   APPL|  Linda|  130|\n",
      "|   APPL|   Mike|  750|\n",
      "|   APPL|  Chris|  350|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a local sqllite DB using JDBC connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### install SQLlite jar file in SPARK_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $SPARK_HOME\n",
    "# curl https://repo1.maven.org/maven2/org/xerial/sqlite-jdbc/3.28.0/sqlite-jdbc-3.28.0.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define driver, path to local .db file, and append that path to jdbc:sqlite to construct the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = \"org.sqlite.JDBC\"\n",
    "path = \"chinook.db\"\n",
    "url = \"jdbc:sqlite:\" + path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### specify the table to be read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename = \"albums\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albums = spark1.read.format(\"jdbc\").option(\"url\",url).option(\"dbtable\",tablename).option(\"driver\",driver).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+\n",
      "|AlbumId|               Title|ArtistId|\n",
      "+-------+--------------------+--------+\n",
      "|      1|For Those About T...|       1|\n",
      "|      2|   Balls to the Wall|       2|\n",
      "|      3|   Restless and Wild|       2|\n",
      "|      4|   Let There Be Rock|       1|\n",
      "|      5|            Big Ones|       3|\n",
      "|      6|  Jagged Little Pill|       4|\n",
      "|      7|            Facelift|       5|\n",
      "|      8|      Warner 25 Anos|       6|\n",
      "|      9|Plays Metallica B...|       7|\n",
      "|     10|          Audioslave|       8|\n",
      "|     11|        Out Of Exile|       8|\n",
      "|     12| BackBeat Soundtrack|       9|\n",
      "|     13|The Best Of Billy...|      10|\n",
      "|     14|Alcohol Fueled Br...|      11|\n",
      "|     15|Alcohol Fueled Br...|      11|\n",
      "|     16|       Black Sabbath|      12|\n",
      "|     17|Black Sabbath Vol...|      12|\n",
      "|     18|          Body Count|      13|\n",
      "|     19|    Chemical Wedding|      14|\n",
      "|     20|The Best Of Buddy...|      15|\n",
      "+-------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_albums.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AlbumId: integer (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- ArtistId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_albums.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albums.createOrReplaceTempView('albums')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read another table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists = spark1.read.format(\"jdbc\").option(\"url\",url).option(\"dbtable\",'artists').option(\"driver\",driver).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|ArtistId|                Name|\n",
      "+--------+--------------------+\n",
      "|       1|               AC/DC|\n",
      "|       2|              Accept|\n",
      "|       3|           Aerosmith|\n",
      "|       4|   Alanis Morissette|\n",
      "|       5|     Alice In Chains|\n",
      "|       6|Antônio Carlos Jobim|\n",
      "|       7|        Apocalyptica|\n",
      "|       8|          Audioslave|\n",
      "|       9|            BackBeat|\n",
      "|      10|        Billy Cobham|\n",
      "|      11| Black Label Society|\n",
      "|      12|       Black Sabbath|\n",
      "|      13|          Body Count|\n",
      "|      14|     Bruce Dickinson|\n",
      "|      15|           Buddy Guy|\n",
      "|      16|      Caetano Veloso|\n",
      "|      17|       Chico Buarque|\n",
      "|      18|Chico Science & N...|\n",
      "|      19|        Cidade Negra|\n",
      "|      20|        Cláudio Zoli|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artists.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists.createOrReplaceTempView('artists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join artists and albums into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = spark1.sql(\"SELECT * FROM albums LEFT JOIN artists ON albums.ArtistId=artists.ArtistId order by artists.ArtistId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+--------+--------------------+\n",
      "|AlbumId|               Title|ArtistId|ArtistId|                Name|\n",
      "+-------+--------------------+--------+--------+--------------------+\n",
      "|      1|For Those About T...|       1|       1|               AC/DC|\n",
      "|      4|   Let There Be Rock|       1|       1|               AC/DC|\n",
      "|      2|   Balls to the Wall|       2|       2|              Accept|\n",
      "|      3|   Restless and Wild|       2|       2|              Accept|\n",
      "|      5|            Big Ones|       3|       3|           Aerosmith|\n",
      "|      6|  Jagged Little Pill|       4|       4|   Alanis Morissette|\n",
      "|      7|            Facelift|       5|       5|     Alice In Chains|\n",
      "|      8|      Warner 25 Anos|       6|       6|Antônio Carlos Jobim|\n",
      "|     34|Chill: Brazil (Di...|       6|       6|Antônio Carlos Jobim|\n",
      "|      9|Plays Metallica B...|       7|       7|        Apocalyptica|\n",
      "|    271|         Revelations|       8|       8|          Audioslave|\n",
      "|     11|        Out Of Exile|       8|       8|          Audioslave|\n",
      "|     10|          Audioslave|       8|       8|          Audioslave|\n",
      "|     12| BackBeat Soundtrack|       9|       9|            BackBeat|\n",
      "|     13|The Best Of Billy...|      10|      10|        Billy Cobham|\n",
      "|     14|Alcohol Fueled Br...|      11|      11| Black Label Society|\n",
      "|     15|Alcohol Fueled Br...|      11|      11| Black Label Society|\n",
      "|     16|       Black Sabbath|      12|      12|       Black Sabbath|\n",
      "|     17|Black Sabbath Vol...|      12|      12|       Black Sabbath|\n",
      "|     18|          Body Count|      13|      13|          Body Count|\n",
      "+-------+--------------------+--------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_combined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global and temporary views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A temporary view does not persist across multiple sessions (SparkSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|ArtistId|                Name|\n",
      "+--------+--------------------+\n",
      "|       1|               AC/DC|\n",
      "|       2|              Accept|\n",
      "|       3|           Aerosmith|\n",
      "|       4|   Alanis Morissette|\n",
      "|       5|     Alice In Chains|\n",
      "|       6|Antônio Carlos Jobim|\n",
      "|       7|        Apocalyptica|\n",
      "|       8|          Audioslave|\n",
      "|       9|            BackBeat|\n",
      "|      10|        Billy Cobham|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artists.createOrReplaceTempView(\"temp_artists\")\n",
    "\n",
    "df_temp = spark1.sql(\"SELECT * FROM temp_artists LIMIT 10\")\n",
    "df_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark2 = SparkSession.builder.appName('SQL2').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_temp = spark2.sql(\"SELECT * FROM temp_artists LIMIT 10\")\n",
    "except:\n",
    "    print(\"Error happened in this execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global views can persist across multiple sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
